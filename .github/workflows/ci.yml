name: Enhanced GPTCache CI

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]
  workflow_dispatch:

jobs:
  test:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: ["3.10", "3.11"]
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ matrix.python-version }}
    
    - name: Cache pip dependencies
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt', '**/pyproject.toml') }}
        restore-keys: |
          ${{ runner.os }}-pip-
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install pytest pytest-cov pytest-xdist
    
    - name: Install package
      run: |
        pip install -e .
    
    - name: Run tests with coverage
      run: |
        pytest tests/ -v --cov=src --cov-report=xml --cov-report=term-missing
    
    - name: Upload coverage reports
      uses: codecov/codecov-action@v3
      with:
        file: ./coverage.xml
        flags: unittests
        name: codecov-umbrella
        fail_ci_if_error: false

  benchmark:
    runs-on: ubuntu-latest
    needs: test
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python 3.10
      uses: actions/setup-python@v4
      with:
        python-version: "3.10"
    
    - name: Cache pip dependencies
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt', '**/pyproject.toml') }}
        restore-keys: |
          ${{ runner.os }}-pip-
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    
    - name: Install package
      run: |
        pip install -e .
    
    - name: Generate test dataset
      run: |
        python -m benchmark.generate_queries --out data/ci_dataset.json --count 200 --seed 42
    
    - name: Run benchmark (CI sample)
      run: |
        python -m benchmark.benchmark_runner \
          --dataset data/ci_dataset.json \
          --sample 200 \
          --variants baseline full \
          --output data/ci_benchmark_results.json \
          --no-warmup
    
    - name: Analyze results and generate graphs
      run: |
        python -m benchmark.analyze_results \
          --results data/ci_benchmark_results.json \
          --output data/analysis/
    
    - name: Check that graphs were generated
      run: |
        ls -la data/analysis/
        test -f data/analysis/performance_comparison.png
        test -f data/analysis/latency_distribution.png
    
    - name: Upload benchmark graphs as artifacts
      uses: actions/upload-artifact@v3
      with:
        name: benchmark-graphs-${{ github.run_number }}
        path: |
          data/analysis/performance_comparison.png
          data/analysis/latency_distribution.png
          data/analysis/benchmark_report.md
        retention-days: 30
    
    - name: Upload benchmark results
      uses: actions/upload-artifact@v3  
      with:
        name: benchmark-results-${{ github.run_number }}
        path: |
          data/ci_benchmark_results.json
          data/ci_benchmark_results_summary.csv
        retention-days: 30

  docker-test:
    runs-on: ubuntu-latest
    needs: test
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Build Docker image
      run: |
        docker build -t enhanced-gptcache -f docker/Dockerfile .
    
    - name: Test Docker container
      run: |
        docker run --rm enhanced-gptcache python -c "import src.cache.enhanced_cache; print('Enhanced GPTCache imported successfully')"
    
    - name: Run tests in Docker
      run: |
        docker run --rm enhanced-gptcache pytest tests/ -v
    
    - name: Generate dataset in Docker
      run: |
        docker run --rm -v $PWD/data:/app/data enhanced-gptcache \
          python -m benchmark.generate_queries --out data/docker_dataset.json --count 50
    
    - name: Run mini benchmark in Docker
      run: |
        docker run --rm -v $PWD/data:/app/data enhanced-gptcache \
          python -m benchmark.benchmark_runner \
          --dataset data/docker_dataset.json \
          --sample 50 \
          --variants baseline full \
          --output data/docker_results.json \
          --no-warmup

  lint:
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python 3.10
      uses: actions/setup-python@v4
      with:
        python-version: "3.10"
    
    - name: Install linting tools
      run: |
        python -m pip install --upgrade pip
        pip install black isort flake8 mypy
    
    - name: Check code formatting with black
      run: |
        black --check --diff src/ benchmark/ tests/
    
    - name: Check import sorting with isort
      run: |
        isort --check-only --diff src/ benchmark/ tests/
    
    - name: Lint with flake8
      run: |
        flake8 src/ benchmark/ tests/ --max-line-length=100 --extend-ignore=E203,W503
    
    - name: Type check with mypy (optional)
      run: |
        mypy src/ --ignore-missing-imports --no-strict-optional
      continue-on-error: true

  security:
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python 3.10
      uses: actions/setup-python@v4
      with:
        python-version: "3.10"
    
    - name: Install security tools
      run: |
        python -m pip install --upgrade pip
        pip install safety bandit
    
    - name: Check for known vulnerabilities
      run: |
        pip install -r requirements.txt
        safety check
    
    - name: Run security linting with bandit
      run: |
        bandit -r src/ -f json -o bandit-report.json
      continue-on-error: true
    
    - name: Upload security report
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: security-report
        path: bandit-report.json
        retention-days: 30
